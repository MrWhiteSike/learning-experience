kafka集群搭建与使用

1、安装前的环境准备

kafka是Scala语言开发的，运行在jvm上，需要先安装JDK。
kafka依赖zookeeper，需要先安装zookeeper

2、下载安装包
	下载相应版本，并解压
	wget https://archive.apache.org/dist/kafka/2.6.0/kafka_2.13-2.6.0.tgz
	tar -zxvf kafka_2.13-2.6.0.tgz
	mv kafka_2.13-2.6.0 kafka
	

3、创建kafka消息目录，存放kafka消息
cd kafka
mkdir kafka-logs

4、修改配置
cd /opt/module/kafka/config
vim server.properties
需要修改的参数：
broker.id=0  #集群内全局唯一，每台服务器设置不同的值
listeners=PLAINTEXT://192.168.xx.xx:9092 #这个IP地址也是与本机相关的，每台服务器上设置为自己的IP地址
log.dirs=/opt/module/kafka/kafka-logs #存放kafka消息
zookeeper.connect=192.168.xx.xx:2181,192.168.xx.xx:2181,192.168.xx.xx:2181 #zookeeper集群

5、拷贝安装目录
分发kafka目录到集群所有服务器，同时修改每个文件的broker.id 和listeners
比如：scp -r /opt/module/kafka/ root@192.168.xx.xx:/opt/module

6、先启动zookeeper集群
参见zookeeper集群搭建

7、启动集群所有服务器上的kafka
cd /opt/module/kafka
./bin/kafka-server-start.sh -daemon config/server.properties

8、测试
cd /opt/module/kafka

创建主题
./bin/kafka-topics.sh --create --bootstrap-server 192.168.36.121:9092 --replication-factor 3 --partitions 3 --topic test01

查看主题列表（在集群的各个节点都可以看到主题列表）
./bin/kafka-topics.sh --list --bootstrap-server 192.168.36.121:9092
./bin/kafka-topics.sh --list --bootstrap-server 192.168.36.122:9092
./bin/kafka-topics.sh --list --bootstrap-server 192.168.36.123:9092

启动控制台生产者
./bin/kafka-console-producer.sh --broker-list 192.168.36.121:9092 --top
ic test01

启动控制台消费者
./bin/kafka-console-consumer.sh --bootstrap-server 192.168.36.122:9092 --topic test01 --from-beginning

然后在生产者控制台输入 hello kafka
消费者控制台，就可以消费到生产者的消息，输出hello kafka

至此，kafka集群搭建完成！




配置详解：

broker.id=0
#每个 broker 都可以用一个唯一的非负整数 id 进行标识； 这个 id 可以作为 broker 的“名字”， 并且它的存在使得 broker 无须混淆 consumers
#就可以迁移到不同的 host/port 上。 你可以选择任意你喜欢的数字作为 id， 只要 id 是唯一的即可

listeners=PLAINTEXT://192.168.xx.xx:9092
#Kafka服务地址

#advertised.listeners=PLAINTEXT://your.host.name:9092
#Kafka注册到Zookeeper的地址，内网不用设置默认使用listeners，
#内外网环境
#listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
#listeners=INTERNAL://192.168.xx.xx:9092,EXTERNAL://192.168.xx.xx:9093
#advertised.listeners=INTERNAL://192.168.xx.xx:9092,EXTERNAL://<公网ip>:<端口>
#inter.broker.listener.name=INTERNAL

num.network.threads=3
# broker 处理消息的最大线程数，一般情况下不需要去修改

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

socket.send.buffer.bytes=102400
#SO_SNDBUFF 缓存大小， server 进行 socket连接所用

socket.receive.buffer.bytes=102400
#SO_RCVBUFF 缓存大小， server 进行 socket连接时所用

socket.request.max.bytes=104857600
#server允许的最大请求尺寸； 这将避免server溢出， 它应该小于 Java heap size

log.dirs=/opt/module/kafka/kafka-logs
#kafka 存放数据的路径。这个路径并不是唯一的，可以是多个， 路径之间只需要使用逗号分隔即可； 
#每当创建新 partition 时， 都会选择在包含最少 partitions 的路径下进行。

num.partitions=3
#如果创建 topic 时没有给出划分 partitions 个数， 这个数字将是 topic 下 partitions 数目的默认数值。

num.recovery.threads.per.data.dir=1
#每个数据目录用来日志恢复的线程数目

offsets.topic.replication.factor=3
#topic 的 offset 的备份份数。 建议设置更高的数字保证更高的可用性
transaction.state.log.replication.factor=3
#事务主题的复制因子（设置更高以确保可用性）。 内部主题创建将失败，直到群集大小满足此复制因素要求。
transaction.state.log.min.isr=3
#覆盖事务主题的min.insync.replicas配置。


#log.flush.interval.messages=10000
#此项配置指定时间间隔： 强制进行 fsync日志。 例如， 如果这个选项设置为 1， 那么每条消息之后都需要进行 fsync， 
#如果设置为 5， 则每 5 条消息就需要进行一次fsync。 一般来说， 建议你不要设置这个值。 

#log.flush.interval.ms=1000
#此项配置用来置顶强制进行 fsync 日志到磁盘的时间间隔； 例如， 如果设置为1000， 那么每 1000ms 就需要进行一次fsync。 一般不建议使用这选项

log.retention.hours=168
#log.retention.bytes=1073741824
#每个日志文件删除之前保存的时间。 默认数据保存时间对所有 topic 都一样。
#log.retention.hours和log.retention.bytes 都是用来设置删除日志文件的， 无论哪个属性已经溢出。
#这个属性设置可以在 topic 基本设置时进行覆盖。

log.segment.bytes=1073741824
#topic partition 的日志存放在某个目录下诸多文件中， 这些文件将 partition 的日志切分成一段一段的； 这个属性就是每个文件的最大尺寸；
#当尺寸达到这个数值时， 就会创建新文件。 此设置可以由每个 topic 基础设置时进行覆盖。

log.retention.check.interval.ms=300000
#检查日志分段文件的间隔时间， 以确定是否文件属性到达删除要求

zookeeper.connect=10.160.22.1:2181,10.160.22.2:2181,10.160.22.3:2181
#zookeeper集群

zookeeper.connection.timeout.ms=6000
#客户端等待和 zookeeper 建立连接的最大时间

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
#主要作用是让coordinator推迟空消费组接收到成员加入请求后本应立即开启的rebalance。在实际使用时，假设你预估你的所有consumer组成员加入需要在10s内完成，那么你就可以设置该参数=10000。



kafka集群启动脚本kafka-cluster.sh:


#!/bin/bash

case $1 in
"start"){
	for i in hadoop1 hadoop2 hadoop3
	do 
		 echo -------------------------------- $i kafka 启动 ---------------------------
		ssh $i "source /etc/profile;/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
	done
}
;;
"stop"){
	for i in hadoop1 hadoop2 hadoop3
	do
		echo -------------------------------- $i kafka 停止 ---------------------------
		ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh"
	done
}
;;
esac


注意：source /etc/profile; （重要）Java环境所在地方
在这个文件需要导入java环境，即
export JAVA_HOME=/usr/java/jdk1.8.0_131
export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar
export PATH=$PATH:$JAVA_HOME/bin


启动kafka集群的命令：
./kafka-cluster.sh start

停止kafka集群的命令：
./kafka-cluster.sh stop


	
