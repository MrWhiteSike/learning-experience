Spark运行环境

主流环境为Yarn
容器式环境慢慢流行


本地运行模式
独立运行模式
Yarn运行模式

分发命令：
xsync 目录

查看进程：
xcall jps

提交应用命令：

bin/spark-submit \
-- class 
-- master 
./XXX.jar 参数1 参数2 ...


class：表示要执行程序的主类
master：指定运行环境，连接到Spark集群，比如： local[*], spark://linux:7077, Yarn
xxx.jar： 运行类的所在的jar包
参数1：表示程序的入口参数，用于设定当前应用的任务数量


--executor-memory 1G : 指定每个executor可用内存为1G
--total-executor-cores 2 ：指定所有executor使用的cpu核数为2个
--executor-cores 5： 指定每个executor使用的cpu核数


配置历史服务，可以查看历史任务运行情况

容器化部署是业界流行的一项技术：
基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。
容器管理工具中最为流行的就是Kubernetes（K8s）
而spark也在最近的版本中支持了k8s部署模式。


总结：
部署模式对比：
模式|Spark安装机器数|需要启动进程|所属者|应用场景
Local 1 无  Spark 测试
Standalone 3 Master及Worker Spark 单独部署
Yarn 1 Yarn以及HDFS Hadoop 混合部署









