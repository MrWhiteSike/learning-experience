Spark核心编程

Spark计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景，三大数据结构分别是：
RDD：弹性分布式数据集
累加器：分布式共享只写变量
广播变量：分布式共享只读变量


RDD，Resilient Distributed Dataset
弹性分布式数据集，是spark中最基本的数据处理模型。最小的数据处理单元。
代码中是一个抽象类，代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。
是一种数据准备好，逻辑准备好的数据结构。组织、存储的结构

弹性：
存储的弹性：内存与磁盘的自动切换
容错的弹性：数据丢失可以自动恢复
计算的弹性：计算出错重试机制
分片的弹性：可根据需要重新分片

在Driver中把RDD分解成不同的Task发给Executor去执行计算。


IO模型中：
字节流：提升性能的方式是：添加一个缓冲区buffer，当数据达到阈值时，才会输出到下游。
字符流：一行一行读，需要用到字节流转字符流的转换流InputStreamReader/OutputStreamWriter

装饰者设计模式，核心没变，在外层进行了包装，在之前的基础上扩展更强大的功能。
FileInputStream 读取字节-- InputStreamReader 字节转字符 -- BufferedFileReader 缓存字符
逐层功能的叠加
延迟加载的感觉


WordCount：

file --> HadoopRDD-textFile --> MapPartitionsRDD-flatMap --> MapPartitionsRDD-map --> ShuffledRDD-reduceByKey --> collect --> console

RDD与IO流的异同：

RDD的数据处理方式类似于IO流，也有装饰者设计模式。
RDD的数据只有在调用collect方法时，才会真正执行业务逻辑操作，之前的封装全部都是功能的扩展。
RDD是不保存数据的，但是IO可以临时保存一部分数据。




分布式：数据存储在大数据集群不同节点上
数据集：RDD封装了计算逻辑，并不保存数据
数据抽象：RDD是一个抽象类，需要子类具体实现
不可变：RDD封装了计算逻辑，是不可以改变的，想要改变，只能产生新的的RDD，在新的RDD里面封装计算逻辑
可分区、并行计算

RDD 核心属性
1、分区列表
RDD数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。
getPartitions

2、分区计算函数
Spark在计算时，是使用分区函数对每一个分区进行计算
compute

3、RDD之间的依赖关系
RDD是计算模型的封装，当需求中需要将多个计算模型进行组合时，就需要将多个RDD建立依赖关系，就会形成一个列表
getDependices

4、分区器Partitioner
分区规则

5、首选位置
判断计算发送到哪个节点，效率最优
getPreferredLocations

移动数据不如移动计算。



执行原理























