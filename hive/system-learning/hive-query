hive-query

全表和特定列查询：

注意：
1、sql语言大小写不敏感
2、SQL可以写在一行或者多行
3、关键字不能被缩写也不能分行
4、各子句一般要分行写
5、使用缩进提高语句的可读性。


列别名：
重命名一个列
便于计算
紧跟列名，也可以在列名和别名之前加入关键字 as




算术运算符：
a+b 相加
a-b 减法
a*b 乘法
a/b 除法
a%b 取余
a&b 按位与
a|b 按位或
a^b 按位异或
~a 取反



常用函数：
count：求总行数
max：求最大值
min：求最小值
sum：求总和
avg：求平均


limit语句：
查询返回多行数据，用于限制返回的行数。
limit 5


where语句：
使用where子句，将不满足条件的行进行过滤掉
where子句紧跟from子句
注意：where子句不能使用字段别名。
执行顺序：from -> where -> select


比较运算符：
a=b  a等于b返回true，反之返回false
a<=>b  a和b都为null，返回true，如果一边为null，返回false
a<>b, a!=b a或者b为null，返回null；如果a不等于b，则返回true，反之返回false
a<b a或者b为null，则返回null；如果a小于b，则返回true，反之返回false
a<=b a或者b为null，则返回null；如果a小于等于b，则返回true，反之返回false
a>b a或者b为null，则返回null；如果a大于b，则返回true，反之返回false
a>=b a或者b为null，则返回null；如果a大于等于b，则返回true，反之返回false
a [not] between b and c 如果a，b，c任一个为null，则结果为null。
如果a的值大于等于b而且小于等于c，则结果为true，反之false。
如果使用not关键字则可达到相反的效果。
a is null：判断是否为null

a is not null : 如果a不等于Null，则返回true，反之返回false
in (val1, val2,...)

Like 和 Rlike：
使用Like运算符选择类似的值：
选择条件可以包含字符或者数字
% 代表零个或者多个字符（任意个字符）
_代表一个字符

a [not] like b: 仅字符串类型适用
 b是一个SQL下的简单正则表达式，也叫通配符模式，如果a与其匹配的话，则返回true；反之返回false。b的表达式说明如下： 'x%' 表示a必须以字母x开头，'%x'表示a必须以字母'x'结尾；
'%x%'表示a包含字母x，可以位于开头，结尾或者字符串中间。如果使用not关键字则可达到相反的效果。

a rlike b, a regexp b: 适用于字符串类型
b是基于Java的正则表达式，如果a与其匹配，则返回true；反之返回false。匹配使用的是jdk中的正则表达式接口。



逻辑运算符：
and ： 逻辑并
or：逻辑或
not：逻辑否



分组：
group by语句

group by语句通常会和聚合函数一起使用，按照一个或者多个队列结果进行分组，然后对每个组执行聚合操作。


having 语句：

having 与 where 不同点：
	1）where后面不能写分组函数，而having 后面可以使用分组函数
	2）having只用于group by分组统计语句。

例子：
select name from table group by name having min(fenshu) >= 80; 




Join 语句：
1.等值join
2.表的别名
3.内连接
select 
	e.empno,
	e.ename,
	e.deptno,
	d.dname
from 
	emp e
join 
	dept d 
on e.deptNo = d.deptNo;
4.左外连接
select 
	e.empno,
	e.ename,
	e.deptno,
	d.dname
from 
	emp e
left join 
	dept d 
on e.deptNo = d.deptNo;
5.右外连接
select 
	e.empno,
	e.ename,
	d.deptno,
	d.dname
from 
	emp e
right join 
	dept d 
on e.deptNo = d.deptNo;
6.满外连接、全外连接
使用nvl(,)函数实现前一个为null，使用后一个；后一个为null，使用前一个；

select 
	e.empno,
	e.ename,
	nvl(e.deptno,d.deptNo),
	d.dname
from 
	emp e
full join 
	dept d 
on e.deptNo = d.deptNo;

7.多表连接

8.笛卡尔积
	1）省略连接条件
	2）连接条件无效
	3）所有表中的所有行互相连接

9.左表差集
方式1：通过from a left join b on a.field1 = b.field1 where b.field1 is null;
select 
	e.empno,
	e.ename,
	e.deptno,
	d.dname
from 
	emp e
left join 
	dept d 
on e.deptNo = d.deptNo
where d.deptNo is null;
方式2：通过子查询的方式
select
	e.empno,
	e.ename,
	e.deptno
from
	emp e
where e.deptNo not in 
	(
		select deptNo from dept
		)


10.右表差集
方式1：
select
	d.deptno,
	d.dname
from 
	emp e
right join 
	dept d 
on e.deptNo = d.deptNo
where e.deptNo is null;


方式2：
select
	d.deptno,
	d.dname
from 
	dept d
where d.deptNo not in 
	(select deptNo from emp);

11.左表差集和右表差集；或者说是全连接去除中间重复部分
方式1：
select 
	e.empno,
	e.ename,
	nvl(e.deptno,d.deptNo),
	d.dname
from 
	emp e
full join 
	dept d 
on e.deptNo = d.deptNo;
where e.deptNo is null or d.deptNo is null;

方式2：union连接两张表，两张表的字段必须相同

union 会去重
union all ： 不去重
需求本身不存在重复数据，使用union，union all效果相同，使用union all，效率更高。


select 
	* 
from
(select 
	e.empno,
	e.ename,
	e.deptno as eno,
	d.deptno as dno,
	d.dname
from 
	emp e
left join 
	dept d 
on e.deptNo = d.deptNo
union all
select 
	e.empno,
	e.ename,
	e.deptno as eno,
	d.deptno as dno,
	d.dname
from 
	emp e
right join 
	dept d 
on e.deptNo = d.deptNo) tmp;




order by语句：
order by ： 全局排序，只有一个reducer
asc：升序默认
desc：降序

order by 子句在 select 语句结尾


sort by ： 分区内排序

distribute by： 在有些情况下，我们需要控制某个特定行应该到哪个reducer
通常是为了进行后续的聚集操作。
类似于mr中的partition 进行分区（自定义分区），结合sort by使用。

一定要分配多个reduce进行处理，否则无法看到distribute by的效果。


cluster by：
当distribute by和sort by字段相同时，可以使用cluster by方式。
cluster by除了具有distribute by 的功能还具有sort by的功能。但是
排序只能是升序排序。不能指定排序规则为asc 或者desc。





分区表和分区桶：
分区表(partitioned by)
实际上就是对应一个hdfs文件系统上独立的文件夹，该文件夹下是该
分区所有的数据文件。
Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。
在查询时通过where子句中的表达式选择查询所需要的指定分区。这样的查询效率会提高很多。

分区字段和其他字段不同：
分区字段是分区目录，不在数据文件中，而是在元数据中
其他字段存储在数据文件中。

查询数据指定分区，可以提高查询效率。


创建分区表：
例子，
create table dept_par(deptno int, dname string, loc string)
partitioned by (day string)
row format delimited fields terminated by '\t';

分区表就是为了提高查询效率的，不会进行全表扫描，只会根据指定分区的目录下的数据进行扫描。
注意：where 子句中表达式选择需要指定分区；

增加分区：
单个分区
alter table dept_par add partition(day='20200506');
多个分区
alter table dept_par add partition(day='20200507') partition(day='20200508');


删除分区：
单个分区
alter table dept_par drop partition(day='20200506');
多个分区
alter table dept_par drop partition(day="20200507"),partition(day='20200508');

查看分区表的分区：
show partitions dept_par;

查看分区表的结构：
desc formatted dept_par;


二级分区： 
create table dept_par2(deptno int, dname string, loc string)
partitioned by (day string,hour string)
row format delimited fields terminated by '\t';


修复分区：
方式1：put 数据后，再修复
msck repair table dept_par;

方式2：添加分区
alter table dept_par add partition(day='20200908',hour="14")


方式3：创建文件夹后load数据到分区
load data local inpath '' into table dept_par2 partition(day='20200506',hour='23');


动态分区：
1.开启动态分区功能默认true，开启
hive.exec.dynamic.partition=true
2.设置为非严格模式，动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。
设置属性hive.exec.dynamic.partition.mode=nonstrict
3.在所有mr的节点上，最大一共可以创建多少个动态分区，默认1000
hive.exec.dynamic.partitions=1000
4.在每个执行mr的节点上，最大可以创建多少个动态分区。
该参数需要根据实际的数据来指定。比如，数据中包含了一年的数据
即day字段有365个值，那么该参数就需要设置成365，如果使用默认值100，则会报错。
hive.exec.max.dynamic.partitions.pernode=100
5.整个mrjob中，最大可以创建多少个hdfs文件，默认100000
hive.exec.max.created.files=100000
6.当有空分区生成时，是否抛出异常。一般不需要设置，默认false
hive.error.on.empty.partition=false

默认最后一个字段为分区字段
insert into table dept_par2 partition(deptno)
select dname,loc,deptno from dept;
hive3中的新功能：
insert into table dept_par2
select dname,loc,deptno from dept;



分桶表：
分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据
数据集都可以形成合理的分区对于一张表或者分区，hive可以进一步
组织成桶，也就是更为细粒度的数据范围划分。

分桶是将数据集分解成更容易管理的若干部分的另一个技术。
分区针对的是数据的存储路径；分桶针对的是数据文件。

分区表的字段单独定义
分桶表的字段使用定义中的字段

建表语句：
create table stu_buck(id int, name string)
cluster by(id) --指定分桶字段
into 4 buckets -- 指定分桶个数
row format delimited fields terminated by '\t';
查看表结构：
desc formatted stu_buck;

导入数据到分通表，load方式：
load data inpath '' into table stu_buck;

分桶规则：
hive的分桶采用对分桶字段的值进行hash，然后除以桶的个数取余的
方式决定该条记录存放哪个桶当中。

分桶表操作的注意事项：
1.reduce 个数设置为-1，让job自行决定需要用多少个reduce或者
将reduce个数设置为大于等于分桶表的桶数。
2.从hdfs中load数据到分桶表中，避免本地文件找不到问题
3.不要使用本地模式

insert 方式将数据导入分桶表：
	insert into table stu_buck select * from student;


抽样查询：
对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是
全部结果。
hive可以通过对表进行抽样来满足这个需求。
语法：tablesample(bucket x out of y)

select * from stu_buck tablesample(bucket 1 out of 4 on id);

注意：x的值必须小于等于y的值，否则报错。




函数：

三种：
udf 一进一出  拼接; 可以任意嵌套的
udaf 多进一出 聚合
udtf 一进多出 拆分

多：指输入数据的行数

1.查看系统自带函数
show functions;

2.显示自带函数的用法
desc function upper;

3.详细显示自带的函数用法
desc function extended upper;

常用的内置函数：
1.空字段赋值
	nvl，给值为null的数据赋值，
	格式：nvl（value，default_value）
	功能：如果value为null，则nvl函数返回default_value的值。否则返回value
注意：default_value可以写死，也可以写一个字段；


2.case when then else end


name dept_id 	sex 
张三 	A 	  	男
李四		A 		男
王五 	B 		男
凤姐 	A 		女
御姐 	B 		女
萝莉 	B 		女

需求：求出不同部门男女各多少人，结果如下：
dept_id 男 女
A       2  1
B       1  2
方式1：case语句，适用于多个分支
select 
	dept_id
	sum(case sex when '男' then 1 else 0 end) maleCount,
	sum(case sex when '女' then 1 else 0 end) femaleCount
from
	emp_sex
group by dept_id;

方式2：if语句，只用两个分支
select 
	dept_id
	sum(if(sex='男',1,0)) maleCount,
	sum(if(sex='女',1,0)) femaleCount
from
	emp_sex
group by dept_id;



3.行转列
concat(string A/col, string B/col,...):
返回输入字符串连接后的结果，支持任意个输入字符串；
select concat('a','-','b','-','c');  ==> a-b-c
select concat(deptno,'-',dname) from dept;

concat_ws(separator,str1|Array[string],str2,...);
它是一个特殊形式的concat(), 第一个参数为剩余参数间的分隔符。
分隔符可以是与剩余参数一样的字符串。
如果分隔符是null，返回值也将是null。
这个函数会跳过分隔符参数后的任何null和空字符串。分隔符将被加到被连接的字符串之间。
UDF 

concat_ws('-','a','b','c'); ==> a-b-c
select concat_ws('-',friends) from test;

collect_set(col)：函数只接受基本数据类型，主要作用是将某字段的值进行去重汇总，
产生Array类型字段。这是一个聚合函数。多进一出。UDAF 
collect_list(col): 不去重，产生Array类型字段。

例子：
create table person_info(
name string,
constellation string,
blood_type string
)
row format delimited fields terminated by '\t';

数据:
张三 	白羊座 	  	A
李四		射手座 		A
王五 	白羊座 		B
凤姐 	白羊座 		A
御姐 	射手座 		A
萝莉 	白羊座 		B

需求：把星座和血型一样的人归类到一起
结果如下：
射手座,A   李四|御姐
白羊座,A   张三|凤姐
白羊座,B   王五|萝莉

第一步：将星座和血型拼接在一起
select
	concat(constellation,",",blood_type) con_blood,
	name
from person_info; t1

第二步：聚合相同星座血型的人的姓名
select
	con_blood,
	collect_set(name) name_arr
from 
(select
	concat(constellation,",",blood_type) con_blood,
	name
from person_info)t1 
group by con_blood;t2

第三步：将相同星座血型的人的姓名进行拼接
select 
	con_blood,
	concat_ws("|",name_arr)
from
(select
	con_blood,
	collect_set(name) name_arr
from 
(select
	concat(constellation,",",blood_type) con_blood,
	name
from person_info)t1 
group by con_blood)t2;


合并：由于UDF函数可以任意嵌套。
将第二步和第三步进行合并：

select
	con_blood,
	concat_ws('|',collect_set(name))
from 
(select
	concat(constellation,",",blood_type) con_blood,
	name
from person_info)t1 
group by con_blood;

4.列转行
explode(col): 将hive一列中复杂的Array或者Map结构拆分成多行。
属于UDTF函数，
lateral view

用法：
lateral view udtf(expression) tableAlias as columnAlias

解释：用于和split，explode等UDTF一起使用，它能够将一列数据拆分成多行数据，在此基础上
可以对拆分后的数据进行聚合。

例子：
create table movie_info(
movie string,
category string)
row format delimited fields terminated by '\t';

数据：
《白日追凶》 悬疑,动作,科幻，剧情
《威龙》 悬疑，警匪，动作，心理，剧情
《战狼 2》 战争，动作，灾难

select split(category,',') from movie_info;

select movie,explode(split(category,',')) from movie_info; 这个语句报错，movie行数和炸裂的行数不同

解决方案：侧写 lateral view 语句
需要跟原表中的字段进行关联的时候，需要对表进行侧写炸裂：
select 
	movie,
	category_name 
from movie_info
lateral view
explode(split(category,',')) movie_info_tmp as category_name;

不需要跟原表中的字段进行关联的时候，直接进行炸裂就可以：
select 
	explode(split(category,',')) 
from movie_info；


5.窗口函数（开窗函数）
over() : 指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化。
是在group by语句之后生效。

current row : 当前行
n preceding：往前n行数据
n following：往后n行数据
unbounded：起点
	unbounded preceding：表示从前面的起点
	unbounded following：表示到后面的终点
lag（col，n，default_val）：往前第n行数据
lead（col，n，default_val）： 往后第n行数据
ntile（n）：把有序窗口的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，ntile
返回此行所属的组的编号。
注意：n必须为int类型

例子：消费流水表
name    orderdate   cost 
jack,2020-01-01,10
tony,2020-01-02,15
jack,2020-02-03,23
tony,2020-01-04,29
jack,2020-01-05,46
jack,2020-04-06,42
tony,2020-01-07,50
jack,2020-01-08,55
mart,2020-04-08,62
mart,2020-04-09,68
neil,2020-05-10,12
mart,2020-04-11,75
neil,2020-06-12,80
mart,2020-04-13,94

需求1：查询在2020年4月份购买过的顾客以及总人数

分析，首先通过substring截取时间字段提取出2020-04的数据
select 
	* 
from business
where substring(orderdate,0,7) = '2020-04';

然后获取顾客名： 可以使用distinct（name）进行去重，也可以使用group by进行去重

select 
  distinct(name)
from business
where substring(orderdate,0,7) = '2020-04';
或者
select 
 	name
from business
where substring(orderdate,0,7) = '2020-04'
group by name;

最后取总人数：
select 
  count(distinct(name))
from business
where substring(orderdate,0,7) = '2020-04';
或者
select
	count(*)
from
(select 
 	name
from business
where substring(orderdate,0,7) = '2020-04'
group by name)t1;

但是顾客名和总人数不在一个语句中输出，怎么办？
select 
 	name,
 	count(*)
from business
where substring(orderdate,0,7) = '2020-04'
group by name; 
==>
jack 1
mart 4
这条语句的结果是我们需要的结果吗？
这个只是求出了顾客名分组后，对分组后的名字出现的次数进行统计，显然不满足现在的需求。

解决方案： 添加over()开窗函数
select 
 	name,
 	count(*) over()
from business
where substring(orderdate,0,7) = '2020-04'
group by name; 

==>
jack 2
mart 2
分析上述的语句：
在group by 分组后得到的数据集t1的每一条数据开了一个窗口，窗口中什么也没有，就是对t1这个数据集的全表数据进行count操作。


select 
 	name,
 	count(*)
from business;
这条语句在hive中会报错，在MySQL中可以执行 结果为jack，14

select 
 	name,
 	count(*) over()
from business;
这条语句在hive中可以正常执行，类似于侧写的效果
==> 14条数据
jack 14
...
mart 14

over()  和 group by 的区别：
over() 其中内容不写的话，就用全表作为数据集，为每一条数据开了一个窗口。



需求2：查询顾客的购买明细以及月购买总额

// 查询顾客的购买明细以及购买总额
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by name) -- 开窗后对顾客进行分组，分组后对购买金额进行sum聚合
from business;

// 查询顾客的购买明细以及顾客月购买总额
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by name,month(orderdate)) -- 开窗后，对顾客以及月份进行分组，分组后对购买金额进行sum聚合
from business;

// 查询顾客的购买明细以及月购买总额(按月进行开窗分组)
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by month(orderdate)) -- 开窗后，对月份进行分组，分组后对购买金额进行sum聚合
from business;


需求3：上述场景，将每个顾客的cost按照日期进行累积
方式1：
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by name order by orderdate)-- partition by一个字段，order by一个字段情况默认是rows between unbounded preceding and current row
from business;


方式2：这种方式和方式1等效
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by name order by orderdate rows between unbounded preceding and current row)
from business;

// 求当前行的前1行和后1行的数据三条数据进行聚合
select
	name,
	orderdate,
	cost,
	sum(cost) over(partition by name order by orderdate rows between 1 preceding and 1 following)
from business;

partition by 在开窗函数中，指定了窗口的范围。order by 是在窗口范围内进行排序，如果不加partition by，窗口范围就是整张表的数据集。


需求4：查询每个顾客上次的购买时间

第三个参数不给，第一条的数据前一条没有数据，就是null
select
	name,
	orderdate,
	lag(orderdate,1) over(partition by name order by orderdate)
from business;

可以给一个默认值
select
	name,
	orderdate,
	lag(orderdate,1,'1970-01-01') over(partition by name order by orderdate)
from business;
也可以用自己的数据进行填充
select
	name,
	orderdate,
	lag(orderdate,1,orderdate) over(partition by name order by orderdate)
from business;

lag :上面的一行往下移
lead：下面的一行往上移，第三参数 不给，最后一条数据null，可以给一个默认值；也可以用自己的数据进行填充
select
	name,
	orderdate,
	lead(orderdate,1,orderdate) over(partition by name order by orderdate)
from business;


需求5：查询前20%时间的订单信息

// 第一步，先进行order by排序，然后分组
select
	name,
	orderdate,
	cost,
	ntile(5) over(order by orderdate) groupId
from business; t1


// 第二步，把第一组的数据拿到，就是前20%
select
	name,
	orderdate,
	cost
from 
(select
	name,
	orderdate,
	cost,
	ntile(5) over(order by orderdate) groupId
from business)t1
where groupId = 1;


6.rank
不能单独使用，后跟over窗口函数使用。

rank() 排序相同时会重复，总数不会变
dense_rank() 排序相同时会重复，总数会减少
row_number() 会根据顺序计算


create table score(
name string,
subject string,
score int)
row format delimited fields terminated by '\t';

数据：
张三  语文   87
张三  数学   95
张三  英语   68
李四  语文   94
李四  数学   56
李四  英语   84
王五  语文   64
王五  数学   86
王五  英语   84
孙六  语文   65
孙六  数学   85
孙六  英语   78

// 对score进行排序，rank() 获取排名，不是密集型的，比如：两个排名都是第 6，后面的数据排名就是 8
select 
	*,
	rank() over(order by score)
from score;

// 密集型的：比如 两个排名都是第 6 ，后面排名就是紧跟着 7 
select 
	*,
	dense_rank() over(order by score)
from score;

// 就是求数据行号
select 
	*,
	row_number() over(order by score)
from score;


需求1:求每个学科成绩top3 属于分组取topN

方式1：利用over 开窗函数实现

// 第一步，就是对学科进行分组，然后对分组的学生成绩进行排名(三个函数都可以使用进行排名)
select 
	*,
	rank() over(partition by subject order by score) rk,
	dense_rank() over(partition by subject order by score) drk,
	row_number() over(partition by subject order by score) rbk
from score; t1

// 第二步：子查询将top3取出
select
	name,
	subject,
	score
from
	(select 
	*,
	rank() over(partition by subject order by score) rk
from score)t1
where rk <= 3;

方式2：不使用over开窗函数实现
自己跟自己关联，关联条件是学科相同，
分数进行比较，分数最高的join后的条数是最多的，然后用子查询将topn取出。

7.其他常用函数


常用日期函数：
unix_timestamp：返回当前或者指定时间的时间戳
select unix_timestamp();--求当前时间戳
select unix_timestamp("2020-08-28","yyyy-MM-dd"); -- 求某个具体时间的时间戳

from_unixtime:将时间戳转为日期格式
select from_unixtime(1649419690);
===> 2022-04-08 20:08:10

current_date: 当前日期
SELECT CURRENT_DATE; 2022-04-08

current_timestamp: 当前的日期+时间
SELECT CURRENT_TIMESTAMP; 2022-04-08 20:18:41

to_date: 抽取日期部分
select to_date('2022-04-08 20:18:41'); 2022-04-08


year：获取年
select year('2022-04-08 20:18:41'); 2022
month：获取月
select month('2022-04-08 20:18:41'); 4
day：获取日
select day('2022-04-08 20:18:41'); 8
hour：获取时
select hour('2022-04-08 20:18:41'); 20
minute：获取分
select minute('2022-04-08 20:18:41'); 18
second：获取秒
select second('2022-04-08 20:18:41'); 41


weekofyear：当前时间是一年中的第几周
select weekofyear('2022-04-08 20:18:41'); 14
dayofmonth：当前时间是一个月中的第几天
select dayofmonth('2022-04-08 20:18:41');8

months_between : 两个日期间的月份
select months_between('2022-04-08','2022-06-08'); -2


add_months: 日期加减月
select add_months('2022-04-08',3);  2022-07-08
select add_months('2022-04-08',-3);  2022-01-08

datediff：两个日期相差的天数
select DATEDIFF('2022-04-18','2022-04-08'); 10 前-后

date_add: 日期加天数
select date_add('2022-04-18',INTERVAL 3 day);  2022-04-21
date_sub: 日期减天数
select date_sub('2022-04-18',INTERVAL 3 day);  2022-04-15


last_day：日期的当月的最后一天
select LAST_DAY('2022-04-18'); 2022-04-30

date_format: 格式化日期
select DATE_FORMAT('2022-04-08 20:18:41','yyyy/MM/dd HH:hh:ss'); 2022/04/08 20:18:41


常用取整函数：
round：四舍五入
select round(3.14); 3
ceil：向上取整
select ceil(3.14); 4
floor：向下取整
select floor(3.14); 3


常用字符串操作函数：
upper：转大写
lower：转小写
length：长度
trim：前后去空格
lpad：向左补齐，到指定长度
rpad：向右补齐，到指定长度select 
select upper('low'); # LOW
select lower('UPPER'); # upper
select length('length'); # 6
select trim(' trim '); # trim
select lpad('lpad',8,'b'); # bbbblpad
select rpad('lpad',8,'b'); # lpadbbbb
regexp_replace:使用正则表达式匹配目标字符串，匹配成功后替换
select regexp_replace('2022/04/30','/','-'); # 2022-04-30


集合操作：
size:集合中元素的个数
map_keys: 返回map中的key
map_values: 返回map中的value
array_contains : 判断array中是否包含某个元素
sort_array: 将array中的元素排序
